{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d2c612-e4c7-4714-a2ba-bebd0acdda56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import h5py\n",
    "from collections import defaultdict\n",
    "\n",
    "from third_party.hloc.hloc import extract_features, extractors, matchers, pairs_from_retrieval, match_features, visualization\n",
    "from third_party.hloc.hloc.extract_features import ImageDataset\n",
    "from third_party.hloc.hloc.localize_sfm import QueryLocalizer, pose_from_cluster\n",
    "from third_party.hloc.hloc.fast_localize import localize\n",
    "from third_party.hloc.hloc.utils import viz_3d, io\n",
    "from third_party.hloc.hloc.utils.base_model import dynamic_load\n",
    "from third_party.hloc.hloc.utils.io import list_h5_names\n",
    "from third_party.hloc.hloc.utils.parsers import names_to_pair\n",
    "\n",
    "import pycolmap\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6910a65b-5c68-4d9d-8dca-56764cd2163f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LOCAL_FEATURE_EXTRACTOR = 'superpoint_aachen'\n",
    "GLOBAL_DESCRIPTOR_EXTRACTOR = 'netvlad'\n",
    "MATCHER = 'superglue'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2282c458-aa20-4f52-9b2d-4bafa4a0cdcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# img_path = '/home/sagar/Repos/spatial-server/data/query_data/Cubicles/d6a0ab62-900e-4b92-8aa8-558e2c888a26/query_image.png' # Lab Front\n",
    "img_path = '/code/data/query_data/Area2300NoYCheck/e3c01aa7-beed-4c48-81b0-dc235f132ba6/query_image.png' # Cubicles\n",
    "dataset_name = 'Area2300NoYCheck'\n",
    "dataset_path = f'/code/data/map_data/{dataset_name}/hloc_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07c2be1-d848-41c1-b1a9-868c6430ab4c",
   "metadata": {},
   "source": [
    "# Slow localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73cc73a-7a95-4b3a-bf1d-df30cb5a7f2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "img_path = Path(img_path)\n",
    "\n",
    "local_feature_conf = extract_features.confs[LOCAL_FEATURE_EXTRACTOR]\n",
    "global_descriptor_conf = extract_features.confs[GLOBAL_DESCRIPTOR_EXTRACTOR]\n",
    "match_features_conf = match_features.confs[MATCHER]\n",
    "\n",
    "dataset = Path(dataset_path)\n",
    "db_global_descriptors_path = (dataset / global_descriptor_conf['output']).with_suffix('.h5')\n",
    "db_local_features_path = (dataset / local_feature_conf['output']).with_suffix('.h5')\n",
    "# Use the scaled reconstruction if it exists\n",
    "db_reconstruction = dataset / 'scaled_sfm_reconstruction'\n",
    "if not db_reconstruction.exists():\n",
    "    db_reconstruction = dataset / 'sfm_reconstruction'\n",
    "db_reconstruction = dataset / 'sfm_reconstruction'\n",
    "db_image_dir = dataset.parents[0] / 'ns_data' / 'images'\n",
    "\n",
    "query_image_name = os.path.basename(img_path)\n",
    "\n",
    "# Query data\n",
    "query_processing_data_dir = Path(os.path.dirname(img_path))\n",
    "query_global_matches_path = query_processing_data_dir / 'global_match_pairs.txt'\n",
    "query_local_match_path = query_processing_data_dir / 'local_match_data.h5'\n",
    "query_results = query_processing_data_dir / 'query_results.txt'\n",
    "\n",
    "# Extarct local features and global descriptor for the new image\n",
    "query_local_features_path = extract_features.main(\n",
    "    conf = local_feature_conf,\n",
    "    image_dir = query_processing_data_dir,\n",
    "    export_dir = query_processing_data_dir,\n",
    "    image_list = [query_image_name]\n",
    ")\n",
    "\n",
    "query_global_descriptor_path = extract_features.main(\n",
    "    conf = global_descriptor_conf,\n",
    "    image_dir = query_processing_data_dir,\n",
    "    export_dir = query_processing_data_dir,\n",
    "    image_list = [query_image_name]\n",
    ")\n",
    "\n",
    "## Use global descriptor matching to get candidate matches\n",
    "nearest_candidate_images = pairs_from_retrieval.save_global_candidates_for_query(\n",
    "    db_descriptors = db_global_descriptors_path,\n",
    "    query_descriptor = query_global_descriptor_path,\n",
    "    query_image_names = [query_image_name],\n",
    "    num_matched = 10,\n",
    "    output_file_path = query_global_matches_path\n",
    ")\n",
    "\n",
    "## Match the query image against the candidate pairs from above\n",
    "match_features.match_from_paths(\n",
    "    conf = match_features_conf,\n",
    "    pairs_path = query_global_matches_path,\n",
    "    match_path = query_local_match_path,\n",
    "    feature_path_q = query_local_features_path,\n",
    "    feature_path_ref = db_local_features_path\n",
    ")\n",
    "\n",
    "## Now we have global candidate and thier mathces. We use this, along with SfM reconstruction to localize the image.\n",
    "reconstruction = pycolmap.Reconstruction(db_reconstruction.__str__())\n",
    "camera = pycolmap.infer_camera_from_image(query_processing_data_dir / query_image_name)\n",
    "ref_ids = [reconstruction.find_image_with_name(r).image_id for r in nearest_candidate_images]\n",
    "conf = {\n",
    "    'estimation': {'ransac': {'max_error': 12}},\n",
    "    'refinement': {'refine_focal_length': True, 'refine_extra_params': True},\n",
    "}\n",
    "localizer = QueryLocalizer(reconstruction, conf)\n",
    "ret, log = pose_from_cluster(\n",
    "    localizer = localizer, \n",
    "    qname = query_image_name, \n",
    "    query_camera = camera, \n",
    "    db_ids = ref_ids, \n",
    "    features_path = db_local_features_path, \n",
    "    matches_path = query_local_match_path,\n",
    "    features_q_path = query_local_features_path\n",
    ")\n",
    "\n",
    "print('Num_inliers: ', ret['num_inliers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1747b0b-345b-4ded-bd39-54e0ab5c7eb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "confidence = log['PnP_ret']['num_inliers'] / log['keypoints_query'].shape[0]\n",
    "print(\"Confidence: \", confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5627e99a-0387-42f9-94bd-b04b64a4c8c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualization.visualize_loc_from_log(\n",
    "    image_dir = query_processing_data_dir, \n",
    "    query_name = query_image_name, \n",
    "    loc = log, \n",
    "    reconstruction = reconstruction, \n",
    "    db_image_dir = db_image_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a295222d-b1a9-4d21-b82e-42fb604cb07e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig = viz_3d.init_figure()\n",
    "# viz_3d.plot_reconstruction(fig, reconstruction, color='rgba(255,0,0,0.5)', points_rgb=True)\n",
    "# pose = pycolmap.Image(tvec=ret['tvec'], qvec=ret['qvec'])\n",
    "# # viz_3d.plot_camera_colmap(fig, pose, camera, color='rgba(0,255,0,0.5)', name=query_image_name, fill=True)\n",
    "# viz_3d.plot_camera_colmap(fig, pose, reconstruction.cameras[1], color='rgba(0,255,0,0.5)', name=query_image_name, fill=True)\n",
    "# # visualize 2D-3D correspodences\n",
    "# inl_3d = np.array([reconstruction.points3D[pid].xyz for pid in np.array(log['points3D_ids'])[ret['inliers']]])\n",
    "# viz_3d.plot_points(fig, inl_3d, color=\"lime\", ps=1, name=query_image_name)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98e0a74-6c48-43f1-b9d1-556b3afcf2a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = viz_3d.init_figure()\n",
    "viz_3d.plot_reconstruction(fig, reconstruction, color='rgba(255,0,0,0.5)', points_rgb=True, cameras = False)\n",
    "\n",
    "# Add the camera\n",
    "pose = pycolmap.Image(tvec=ret['tvec'], qvec=ret['qvec'])\n",
    "viz_3d.plot_camera_colmap(fig, pose, reconstruction.cameras[1], color='rgba(255,255,255,1)', name=query_image_name, fill=True)\n",
    "\n",
    "# visualize 2D-3D correspodences\n",
    "inl_3d = np.array([reconstruction.points3D[pid].xyz for pid in np.array(log['points3D_ids'])[ret['inliers']]])\n",
    "viz_3d.plot_points(fig, inl_3d, color=\"lime\", ps=1, name=query_image_name)\n",
    "\n",
    "# X axis\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x = [0,10],\n",
    "    y = [0,0],\n",
    "    z = [0,0],\n",
    "    line=dict(\n",
    "        color='red',\n",
    "        width=2\n",
    "    )\n",
    "))\n",
    "\n",
    "# Y axis\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x = [0,0],\n",
    "    y = [0,10],\n",
    "    z = [0,0],\n",
    "    line=dict(\n",
    "        color='green',\n",
    "        width=2\n",
    "    )\n",
    "))\n",
    "\n",
    "# Z axis\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x = [0,0],\n",
    "    y = [0,0],\n",
    "    z = [0,10],\n",
    "    line=dict(\n",
    "        color='blue',\n",
    "        width=2\n",
    "    )\n",
    "))\n",
    "    \n",
    "# Add line\n",
    "# for i in range(0,10):\n",
    "#     tvec = [0, i, 0]\n",
    "#     rvec = [45, 0, 0]\n",
    "#     qvec = Rotation.from_euler('xyz', rvec, degrees = True).as_quat()\n",
    "#     fake_camera = reconstruction.cameras[1]\n",
    "#     fake_pose = pycolmap.Image(tvec=tvec, qvec=qvec)\n",
    "#     viz_3d.plot_camera_colmap(fig, fake_pose, fake_camera, color='rgba(255,255,255,1)', name='z', fill=True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd192ca-3dbe-4b1e-88c0-f6117af4b726",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3, suppress = True)\n",
    "\n",
    "def simplify_small_values(arr, tol = 1e-10):\n",
    "    arr[np.abs(arr) < tol] = 0\n",
    "    return arr\n",
    "\n",
    "def homogenize(rotation, translation):\n",
    "    \"\"\"\n",
    "    Combine the (3,3) rotation matrix and (3,) translation matrix to\n",
    "    one (4,4) transformation matrix\n",
    "    \"\"\"\n",
    "    homogenous_array = np.eye(4)\n",
    "    homogenous_array[:3, :3] = rotation\n",
    "    homogenous_array[:3, 3] = translation\n",
    "    return homogenous_array\n",
    "\n",
    "def rot_from_qvec(qvec):\n",
    "    # Change (w,x,y,z) to (x,y,z,w)\n",
    "    return Rotation.from_quat([qvec[1], qvec[2], qvec[3], qvec[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3a2ca8-c475-4fef-8b24-769a9224bf23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "def convert_hloc_to_blender_frame(matrix):\n",
    "    # Add 180 degrees to X - change in convention\n",
    "    matrix = np.array(matrix)\n",
    "    euler_xyz = Rotation.from_matrix(matrix[:3, :3]).as_euler(\"xyz\", degrees = True)\n",
    "    euler_xyz[0] += 180\n",
    "    rotmat = Rotation.from_euler('xyz', euler_xyz, degrees = True).as_matrix()\n",
    "    matrix[:3, :3] = rotmat\n",
    "    return matrix\n",
    "\n",
    "def convert_blender_to_aframe_frame(matrix):\n",
    "    # Rotate -90 degrees along x-axis\n",
    "    T_B_to_A = np.eye(4)\n",
    "    T_B_to_A[:3,:3] = Rotation.from_euler('xyz', [-90,0,0], degrees = True).as_matrix()\n",
    "    return T_B_to_A @ matrix\n",
    "\n",
    "def get_arscene_pose_matrix(aframe_camera_pose, hloc_camera_matrix, dataset_name):\n",
    "    blender_camera_matrix = convert_hloc_to_blender_frame(hloc_camera_matrix)\n",
    "    blender_camera_matrix_in_aframe = convert_blender_to_aframe_frame(blender_camera_matrix)\n",
    "\n",
    "    aframe_camera_matrix = np.array(aframe_camera_pose).reshape((4,4)).T\n",
    "\n",
    "    arscene_pose_aframe = aframe_camera_matrix @ np.linalg.inv(blender_camera_matrix_in_aframe)\n",
    "\n",
    "    return arscene_pose_aframe.T.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d79969f-70e1-4fc2-94e8-59f7c8e97552",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hloc_camera_matrix = np.linalg.inv(homogenize(rot_from_qvec(ret['qvec']).as_matrix(), ret['tvec']))\n",
    "blender_camera_matrix = convert_hloc_to_blender_frame(hloc_camera_matrix)\n",
    "blender_camera_matrix_in_aframe = convert_blender_to_aframe_frame(blender_camera_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b29cf7-e108-4d03-9814-2f77b8b6bff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "blender_camera_matrix_in_aframe.T.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884ffcfa-b7cd-4017-a4e5-97135cec9af2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read aframe camera matrix from the saved file\n",
    "aframe_camera_file = Path(img_path).parent / 'aframe_camera_matrix_world.pkl'\n",
    "with open(aframe_camera_file, 'rb') as f:\n",
    "    aframe_camera_matrix = pickle.load(f)\n",
    "    aframe_camera_matrix = np.array(aframe_camera_matrix).reshape((4,4)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ad7c49-29e2-4a7d-a8ad-3c6ab79515b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arscene_pose_aframe = aframe_camera_matrix @ np.linalg.inv(blender_camera_matrix_in_aframe) #@ convert_blender_to_aframe_frame(np.eye(4))\n",
    "arscene_pose_aframe.T.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bbc90f-0977-426d-a8a1-7fefe8602b00",
   "metadata": {},
   "source": [
    "# Fast localization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e604fd30-7d1e-45b9-b96d-74e33b081842",
   "metadata": {},
   "source": [
    "Things needed in memory:\n",
    "- Image\n",
    "- Local feature extractor (Superpoint)\n",
    "- Global descriptor (NetVLad)\n",
    "- Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61e7952-a32e-48eb-93df-e04527daaaff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Load global memory - Common data across all maps\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Load local feature extractor model (Superpoint)\n",
    "local_feature_conf = extract_features.confs[LOCAL_FEATURE_EXTRACTOR]\n",
    "Model = dynamic_load(extractors, local_feature_conf['model']['name'])\n",
    "local_features_extractor_model = Model(local_feature_conf['model']).eval().to(device)\n",
    "\n",
    "# Load global descriptor model (Netvlad)\n",
    "global_descriptor_conf = extract_features.confs[GLOBAL_DESCRIPTOR_EXTRACTOR]\n",
    "Model = dynamic_load(extractors, global_descriptor_conf['model']['name'])\n",
    "global_descriptor_model = Model(global_descriptor_conf['model']).eval().to(device)\n",
    "\n",
    "# Load matcher model (SuperGlue)\n",
    "match_features_conf = match_features.confs[MATCHER]\n",
    "Model = dynamic_load(matchers, match_features_conf['model']['name'])\n",
    "matcher_model = Model(match_features_conf['model']).eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5c6316-f712-4f7a-a0e9-07e9ecf560f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Load map specific memory\n",
    "\n",
    "# Define database paths\n",
    "dataset = Path(dataset_path)\n",
    "db_local_features_path = (dataset / local_feature_conf['output']).with_suffix('.h5')\n",
    "\n",
    "db_reconstruction = dataset / 'scaled_sfm_reconstruction'\n",
    "if not db_reconstruction.exists():\n",
    "    db_reconstruction = dataset / 'sfm_reconstruction'\n",
    "\n",
    "# Load global descriptors from the database\n",
    "db_global_descriptors_path = (dataset / global_descriptor_conf['output']).with_suffix('.h5')\n",
    "db_image_names = np.array(list_h5_names(db_global_descriptors_path))\n",
    "db_global_descriptors = pairs_from_retrieval.get_descriptors(db_image_names, db_global_descriptors_path)\n",
    "db_global_descriptors = db_global_descriptors.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd8275b-fb66-4780-88b5-5d4324e727b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Localize at query time\n",
    "# Query data\n",
    "img_path = Path(img_path)\n",
    "query_image_name = os.path.basename(img_path)\n",
    "query_processing_data_dir = Path(os.path.dirname(img_path))\n",
    "\n",
    "ret_new, log_new = localize(\n",
    "    query_processing_data_dir = query_processing_data_dir, \n",
    "    query_image_name = query_image_name, \n",
    "    device = device, \n",
    "    local_feature_conf = local_feature_conf, \n",
    "    local_features_extractor_model = local_features_extractor_model, \n",
    "    global_descriptor_conf = global_descriptor_conf, \n",
    "    global_descriptor_model = global_descriptor_model, \n",
    "    db_global_descriptors = db_global_descriptors, \n",
    "    db_image_names = db_image_names,\n",
    "    db_local_features_path = db_local_features_path,\n",
    "    matcher_model = matcher_model,\n",
    "    db_reconstruction = db_reconstruction\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baec0fd5-491c-4736-89e2-7ca66f3bb1c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
